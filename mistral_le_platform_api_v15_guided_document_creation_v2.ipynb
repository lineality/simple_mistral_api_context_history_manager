{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Chat with Mistral API\n",
        "This is a colab-notebook for chatting with a Mistral model. This colab can run on any online device that runs a web browser (phone, tablet, laptop, desktop, etc.).\n",
        "\n",
        "This is a system for using the online cloud Mistral api, not the mistral models run locally in a local pipeline.\n",
        "\n",
        "### Note: Colabs are slower\n",
        "Free colabs are amazing for easily sharing and running code in a portable way,\n",
        "but they are slower. Code in production, or run locally, will be faster than a colab.\n",
        "\n",
        "## mistral-small-latest = Mixtral8x7\n",
        "https://mistral.ai/news/mixtral-of-experts/\n",
        "\n",
        "## Steps:\n",
        "- Configure api-key\n",
        "- Select Model: small-8x7 or open-mistral-7b (optional step)\n",
        "- Select style-prompt to experiment with personality of answer (optional)\n",
        "  - Modify the personality = \"\" text to describe the personality you want.\n",
        "  - Specifying the language of reply can be done in the sytem-prompt\n",
        "- Run all cells [Runtime tab -> run all]\n",
        "- Type text when prompted at bottom of the colab.\n",
        "- Download the saved conversation history if you want. (optional)\n",
        "- Save or download your own copy of the colab under 'File' tab.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ya5gXB9W5e9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### From Mistral docs\n",
        "See:\n",
        "- https://docs.mistral.ai/\n",
        "- https://docs.mistral.ai/platform/client/\n",
        "\n",
        "```\n",
        "curl --location \"https://api.mistral.ai/v1/chat/completions\" \\\n",
        "     --header 'Content-Type: application/json' \\\n",
        "     --header 'Accept: application/json' \\\n",
        "     --header \"Authorization: Bearer $MISTRAL_API_KEY\" \\\n",
        "     --data '{\n",
        "    \"model\": \"mistral-small-latest\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"Who is the most renowned French painter?\"}]\n",
        "  }'\n",
        "```"
      ],
      "metadata": {
        "id": "R6fGLCwKndOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Core API call:\n",
        "## response = requests.post(endpoint_url, headers=headers, json=request_body)\n"
      ],
      "metadata": {
        "id": "f_XNy2pxIjg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Roles and Conversation History\n",
        "\n",
        "\n",
        "## For Simple No-history Mode:\n",
        "```\n",
        "# Set the headers\n",
        "headers = {\n",
        "  \"Content-Type\": \"application/json\",\n",
        "  \"Accept\": \"application/json\",\n",
        "  \"Authorization\": f\"Bearer {mistral_api_key}\"\n",
        "}\n",
        "\n",
        "# Define the request body\n",
        "request_body = {\n",
        "  \"model\": \"mistral-small-latest\",  # 'mistral-small' is 8x7, vs. 'open-mistral-7b' for 7b\n",
        "  \"messages\": [{\"role\": \"user\", \"content\": user_input}]\n",
        "}\n",
        "\n",
        "# Send the request\n",
        "response = requests.post(endpoint_url, headers=headers, json=request_body)\n",
        "\n",
        "# extract just the 'what they said' part out\n",
        "\n",
        "    # Get the response data\n",
        "    response_data = response.json()\n",
        "\n",
        "    # Print the Mistral response\n",
        "\n",
        "    ##\n",
        "    ##\n",
        "    # Turn this print on to see full return data\n",
        "    ##\n",
        "    ##\n",
        "    \"\"\"\n",
        "    e.g.\n",
        "    {\n",
        "      \"id\": \"635cb8d445ujhe5546bb64e5e7\",\n",
        "      \"object\": \"chat.completion\",\n",
        "      \"created\": 170hrjfjf7084,\n",
        "      \"model\": \"open-mistral-7b\",\n",
        "      \"choices\": [\n",
        "        {\n",
        "          \"index\": 0,\n",
        "          \"message\": {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"Enjoy your cup of tea!\"\n",
        "          },\n",
        "          \"finish_reason\": \"stop\",\n",
        "          \"logprobs\": null\n",
        "        }\n",
        "      ],\n",
        "      \"usage\": {\n",
        "        \"prompt_tokens\": 575,\n",
        "        \"total_tokens\": 629,\n",
        "        \"completion_tokens\": 54\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    # print(json.dumps(response_data, indent=2))\n",
        "    # print(type(response_data))\n",
        "\n",
        "    output = response_data\n",
        "    # print(type(output))\n",
        "    # print(type(output[\"choices\"][0]))\n",
        "\n",
        "    # extract just the 'what they said' part out\n",
        "    assistant_says = output[\"choices\"][0]['message']['content']\n",
        "```\n",
        "or\n",
        "## For History Mode:\n",
        "```\n",
        "# Set the headers\n",
        "headers = {\n",
        "  \"Content-Type\": \"application/json\",\n",
        "  \"Accept\": \"application/json\",\n",
        "  \"Authorization\": f\"Bearer {mistral_api_key}\"\n",
        "}\n",
        "\n",
        "\n",
        "conversation_history = [\n",
        "{\"role\": \"system\", \"content\": user_input},\n",
        "{\"role\": \"user\", \"content\": user_input},\n",
        "{\"role\": \"assistant\", \"content\": user_input},\n",
        "{\"role\": \"user\", \"content\": user_input},\n",
        "{\"role\": \"assistant\", \"content\": user_input},\n",
        "{\"role\": \"user\", \"content\": user_input},\n",
        "]\n",
        "\n",
        "# Define the request body\n",
        "request_body = {\n",
        "  \"model\": \"mistral-small-latest\",  # 'mistral-small' is 8x7, vs. 'open-mistral-7b' for 7b\n",
        "  \"messages\": conversation_history\n",
        "}\n",
        "\n",
        "# Send the request\n",
        "response = requests.post(endpoint_url, headers=headers, json=request_body)\n",
        "\n",
        "# extract just the 'what they said' part out\n",
        "\n",
        "    # Get the response data\n",
        "    response_data = response.json()\n",
        "\n",
        "    # Print the Mistral response\n",
        "\n",
        "    ##\n",
        "    ##\n",
        "    # Turn this print on to see full return data\n",
        "    ##\n",
        "    ##\n",
        "    \"\"\"\n",
        "    e.g.\n",
        "    {\n",
        "      \"id\": \"635cb8d445ujhe5546bb64e5e7\",\n",
        "      \"object\": \"chat.completion\",\n",
        "      \"created\": 170hrjfjf7084,\n",
        "      \"model\": \"open-mistral-7b\",\n",
        "      \"choices\": [\n",
        "        {\n",
        "          \"index\": 0,\n",
        "          \"message\": {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"Enjoy your cup of tea!\"\n",
        "          },\n",
        "          \"finish_reason\": \"stop\",\n",
        "          \"logprobs\": null\n",
        "        }\n",
        "      ],\n",
        "      \"usage\": {\n",
        "        \"prompt_tokens\": 575,\n",
        "        \"total_tokens\": 629,\n",
        "        \"completion_tokens\": 54\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    # print(json.dumps(response_data, indent=2))\n",
        "    # print(type(response_data))\n",
        "\n",
        "    output = response_data\n",
        "    # print(type(output))\n",
        "    # print(type(output[\"choices\"][0]))\n",
        "\n",
        "    # extract just the 'what they said' part out\n",
        "    assistant_says = output[\"choices\"][0]['message']['content']\n",
        "```"
      ],
      "metadata": {
        "id": "a7O-canBpLU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### e.g. From mistral 7b (tiny)\n",
        "\n",
        "(User) Say...\n",
        "- What might a kindly French owner of a bakery say in French to a customer?\n",
        "\n",
        "AI:\n",
        "- A kindly French bakery owner might greet the customer with a warm \"Bonjour, mon ami/madame!\" (Good day, sir/madam!), followed by \"Comment allez-vous aujourd'hui?\" (How are you today?). Once the customer places an order, the bakery owner could respond with a friendly \"C'est délicieux que vous choisissez ce brioche/croissant/pain au chocolat!\" (That's delicious that you choose this croissant/brioche/chocolate bread!), or \"Votre gateau/pain/patisserie est prêt/prête pour vous!\" (Your cake/bread/pastry is ready for you!). Before parting ways, the bakery owner would likely wish the customer a nice day, \"A bien jusqu'à demain!\" (Have a nice day!), or \"A votre santé!\" (To your health!).\n",
        "\n",
        "\n",
        "(User) Say...\n",
        "- Bonjour, je voudrais une baguette, s'il vous plaît.  Avez-vous des croissants ?  Je vais prendre un pain au chocolat aussi.\n",
        "\n",
        "AI:\n",
        "- Bonjour! Bien sûr, je peux t'aider. Une baguette et un pain au chocolat, ça va être un plaisir de te les préparer. Et concernant les croissants, désolé(e) mais nous n'en avons pas pour le moment. À tout à l'heure!\n"
      ],
      "metadata": {
        "id": "ZShRJrnjJ6E6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# login"
      ],
      "metadata": {
        "id": "-GtYYzwxHt2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        ".env: get your environment variables:\n",
        "  Using the Google Secretes (like.env) system\n",
        "  built into colab on the left menu: the 'key' icon.\n",
        "\"\"\"\n",
        "from google.colab import userdata\n",
        "mistral_api_key = userdata.get('mistral_api_key')\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Python Dot-env\n",
        "\"\"\"\n",
        "# from dotenv import load_dotenv\n",
        "# import os\n",
        "\n",
        "# load_dotenv()\n",
        "# api_key = os.getenv(\"mistral_api_key\")\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Hard Code (not the best idea)\n",
        "\"\"\"\n",
        "# mistral_api_key = 'xxx'"
      ],
      "metadata": {
        "id": "BghwWvtCHt-7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "eb5cf5ee-bbb5-4c6a-9633-152734733fd4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nHard Code (not the best idea)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "Comment out the model you don't want to use."
      ],
      "metadata": {
        "id": "xjmm0B5nL80T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select Model\n",
        "\"\"\"\n",
        "https://docs.mistral.ai/api/\n",
        "\n",
        "open-mistral-7b\n",
        "\n",
        "open-mixtral-8x22b\n",
        "open-mixtral-8x22b-2404\n",
        "\n",
        "codestral-latest\n",
        "codestral-2405\n",
        "\n",
        "\n",
        "open-mistral-7b\n",
        "(aka mistral-tiny-2312)\n",
        "renamed from mistral-tiny\n",
        "The endpoint mistral-tiny will be deprecated\n",
        "\n",
        "\n",
        "Feb. 26, 2024\n",
        "\n",
        "API endpoints: We renamed 3 API endpoints and added 2 model endpoints.\n",
        "\n",
        "open-mistral-7b (aka mistral-tiny-2312): renamed from mistral-tiny. The endpoint mistral-tiny will be deprecated in three months.\n",
        "open-mixtral-8x7B (aka mistral-small-2312): renamed from mistral-small. The endpoint mistral-small will be deprecated in three months.\n",
        "mistral-small-latest (aka mistral-small-2402): new model.\n",
        "mistral-medium-latest (aka mistral-medium-2312): old model. The previous mistral-medium has been dated and tagged as mistral-medium-2312. The endpoint mistral-medium will be deprecated in three months.\n",
        "mistral-large-latest (aka mistral-large-2402): our new flagship model with leading performance.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "##################\n",
        "# Open Mistral 7b\n",
        "##################\n",
        "# previously \"tiny\"\n",
        "use_this_model = \"open-mistral-7b\"\n",
        "\n",
        "\n",
        "###################\n",
        "# Open Mixtral 8x7\n",
        "###################\n",
        "# previously \"small\"\n",
        "use_this_model = \"open-mixtral-8x7B\"\n",
        "\n",
        "\n",
        "######################\n",
        "# open mixtral 8x22b\n",
        "######################\n",
        "# ...was 'medium'?\n",
        "use_this_model = \"open-mixtral-8x22b\"\n",
        "\n",
        "\n",
        "#######################\n",
        "# Small, Medium, Large  (no 'tiny')\n",
        "#######################\n",
        "use_this_model = \"mistral-small-latest\"\n",
        "use_this_model = \"mistral-medium-latest\"\n",
        "use_this_model = \"mistral-large-latest\"\n",
        "\n",
        "##############\n",
        "# Codestral\n",
        "##############\n",
        "use_this_model = \"codestral-latest\""
      ],
      "metadata": {
        "id": "DLHdP9fqMAIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_this_model = \"open-mistral-7b\""
      ],
      "metadata": {
        "id": "A0OgjAcEXrtj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat W/ History & Saved Files\n",
        "\n",
        "Run all cells."
      ],
      "metadata": {
        "id": "j2nfxcae5plc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Npzlz9WGm549"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "\"\"\"\n",
        "# mistral_api_key = userdata.get('mistral_api_key')\n",
        "\n",
        "# Define the endpoint URL\n",
        "endpoint_url = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "\n",
        "# Set the headers\n",
        "headers = {\n",
        "  \"Content-Type\": \"application/json\",\n",
        "  \"Accept\": \"application/json\",\n",
        "  \"Authorization\": f\"Bearer {mistral_api_key}\"\n",
        "}\n",
        "\n",
        "# mode: [{\"role\": \"user\", \"content\": \"say yes\"}]\n",
        "\n",
        "    # Define the request body\n",
        "    request_body = {\n",
        "      \"model\": \"mistral-small-latest\",\n",
        "      \"messages\": [{\"role\": \"user\", \"content\": user_input}]\n",
        "    }\n",
        "\n",
        "    # Send the request\n",
        "    response = requests.post(endpoint_url, headers=headers, json=request_body)\n",
        "\"\"\"\n",
        "\n",
        "# conversation-history setup\n",
        "context_history = []\n",
        "\n",
        "\n",
        "def print_rec_ai(response, context_history):\n",
        "\n",
        "    # Get the response data\n",
        "    response_data = response.json()\n",
        "\n",
        "    # Print the Mistral response\n",
        "\n",
        "    ##\n",
        "    ##\n",
        "    # Turn this print on to see full return data\n",
        "    ##\n",
        "    ##\n",
        "    \"\"\"\n",
        "    e.g.\n",
        "    {\n",
        "      \"id\": \"635cb8d445ujhe5546bb64e5e7\",\n",
        "      \"object\": \"chat.completion\",\n",
        "      \"created\": 170hrjfjf7084,\n",
        "      \"model\": \"open-mistral-7b\",\n",
        "      \"choices\": [\n",
        "        {\n",
        "          \"index\": 0,\n",
        "          \"message\": {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"Enjoy your cup of tea!\"\n",
        "          },\n",
        "          \"finish_reason\": \"stop\",\n",
        "          \"logprobs\": null\n",
        "        }\n",
        "      ],\n",
        "      \"usage\": {\n",
        "        \"prompt_tokens\": 575,\n",
        "        \"total_tokens\": 629,\n",
        "        \"completion_tokens\": 54\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    # print(json.dumps(response_data, indent=2))\n",
        "    # print(type(response_data))\n",
        "\n",
        "    output = response_data\n",
        "    # print(type(output))\n",
        "    # print(type(output[\"choices\"][0]))\n",
        "\n",
        "    # extract just the 'what they said' part out\n",
        "    assistant_says = output[\"choices\"][0]['message']['content']\n",
        "\n",
        "    # print(assistant_says)\n",
        "\n",
        "    new_comment = {\"role\": \"assistant\", \"content\": assistant_says}\n",
        "\n",
        "    # add what assistant said to context history\n",
        "    context_history.append(new_comment)\n",
        "\n",
        "    return assistant_says, context_history\n",
        "\n",
        "def add_to_context_history(role, comment):\n",
        "\n",
        "    if role == 'user':\n",
        "        segment = {\"role\": \"user\", \"content\": comment}\n",
        "\n",
        "    elif role == 'assistant':\n",
        "        segment = {\"role\": \"assistant\", \"content\": comment}\n",
        "\n",
        "    elif role == 'system':\n",
        "        segment = {\"role\": \"system\", \"content\": comment}\n",
        "\n",
        "    else:\n",
        "        print(\"add_to_context_history(role, comment)\")\n",
        "        print(role, comment)\n",
        "        print('error')\n",
        "\n",
        "    return segment\n",
        "\n",
        "\n",
        "def prompt_user(user_input, context_history):\n",
        "\n",
        "    context_history.append( add_to_context_history(\"user\", user_input) )\n",
        "\n",
        "    return context_history\n",
        "\n",
        "\n",
        "def go_user(user_input, context_history, use_this_model):\n",
        "    \"\"\"\n",
        "    Input: context_history\n",
        "    Ouput Tuple: assistant_says, context_history\n",
        "    \"\"\"\n",
        "\n",
        "    # prompt user\n",
        "    context_history = prompt_user(user_input, context_history)\n",
        "\n",
        "    # prompt assistant\n",
        "    response = ask_mistral_api(context_history, use_this_model)\n",
        "\n",
        "    # ETL: Extract, Transform, & Load\n",
        "    assistant_says, context_history = print_rec_ai(response, context_history)\n",
        "\n",
        "    return assistant_says, context_history\n",
        "\n",
        "\n",
        "def ask_mistral_api(context_history, use_this_model):\n",
        "\n",
        "\n",
        "    # Define the endpoint URL\n",
        "    endpoint_url = \"https://api.mistral.ai/v1/chat/completions\"\n",
        "\n",
        "    # Set the headers\n",
        "    headers = {\n",
        "      \"Content-Type\": \"application/json\",\n",
        "      \"Accept\": \"application/json\",\n",
        "      \"Authorization\": f\"Bearer {mistral_api_key}\"\n",
        "    }\n",
        "\n",
        "    # Define the request body\n",
        "    request_body = {\n",
        "      \"model\": use_this_model,\n",
        "      \"messages\": context_history\n",
        "    }\n",
        "\n",
        "    #################\n",
        "    #################\n",
        "    # Hit the ai api\n",
        "    #################\n",
        "    #################\n",
        "    # Send the request\n",
        "    response = requests.post(endpoint_url, headers=headers, json=request_body)\n",
        "\n",
        "    # Check the response status code\n",
        "    if response.status_code != 200:\n",
        "      raise Exception(f\"Error: {response.status_code} {response.text}\")\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "def simple_ask_mistral_cloud(input_string, use_this_model):\n",
        "    \"\"\"\n",
        "    you have: a string\n",
        "    you need: a response\n",
        "\n",
        "    1. make minimal history contexxt\n",
        "    2. make a generic system instruction, for show\n",
        "    3. make system-user context: string input\n",
        "    4. ask mistral for that model\n",
        "    5. extract just the response string\n",
        "    6. return only reply (no 'history')\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. make minimal history contexxt\n",
        "    context_history = []\n",
        "\n",
        "    # 2. make a generic system instruction\n",
        "    generic_system_instruction = \"You are helpful and answer accurately.\"\n",
        "    context_history.append( add_to_context_history(\"system\", generic_system_instruction) )\n",
        "\n",
        "    # 3. make system-user context: string input\n",
        "    context_history.append( add_to_context_history(\"user\", input_string) )\n",
        "\n",
        "    # 4. ask mistral for that model\n",
        "    response = ask_mistral_api(context_history, use_this_model)\n",
        "\n",
        "\n",
        "    # Get the response data\n",
        "    response_data = response.json()\n",
        "\n",
        "\n",
        "    # 5. extract just the response string\n",
        "\n",
        "    ##\n",
        "    ##\n",
        "    # Turn this print on to see full return data\n",
        "    ##\n",
        "    ##\n",
        "    \"\"\"\n",
        "    e.g.\n",
        "    {\n",
        "      \"id\": \"635cb8d445ujhe5546bb64e5e7\",\n",
        "      \"object\": \"chat.completion\",\n",
        "      \"created\": 170hrjfjf7084,\n",
        "      \"model\": \"open-mistral-7b\",\n",
        "      \"choices\": [\n",
        "        {\n",
        "          \"index\": 0,\n",
        "          \"message\": {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"Enjoy your cup of tea!\"\n",
        "          },\n",
        "          \"finish_reason\": \"stop\",\n",
        "          \"logprobs\": null\n",
        "        }\n",
        "      ],\n",
        "      \"usage\": {\n",
        "        \"prompt_tokens\": 575,\n",
        "        \"total_tokens\": 629,\n",
        "        \"completion_tokens\": 54\n",
        "      }\n",
        "    }\n",
        "    \"\"\"\n",
        "    # print(json.dumps(response_data, indent=2))\n",
        "    # print(type(response_data))\n",
        "\n",
        "    output = response_data\n",
        "    # print(type(output))\n",
        "    # print(type(output[\"choices\"][0]))\n",
        "\n",
        "    # extract just the 'what they said' part out\n",
        "    assistant_says = output[\"choices\"][0]['message']['content']\n",
        "\n",
        "    # 6. return only reply (no 'history')\n",
        "    return assistant_says\n",
        "\n",
        "\n",
        "def strip_non_alpha(text):\n",
        "    # regex to leave only a-z characters\n",
        "    pattern = re.compile('[^a-z]')\n",
        "    return pattern.sub('', text).lower()\n",
        "\n",
        "\n",
        "def keep_talking(context_history, use_this_model):\n",
        "    \"\"\"\n",
        "    A very minimal chat with memory.\n",
        "\n",
        "    Uses:\n",
        "      query(input_string)\n",
        "      strip_non_alpha(text)\n",
        "    \"\"\"\n",
        "    still_talking = True\n",
        "    dialogue_history = \"\"\n",
        "\n",
        "    while still_talking:\n",
        "\n",
        "        user_input = input(\"Say...\")\n",
        "\n",
        "        exit_phrase_list = [\n",
        "            \"exit\",\n",
        "            \"quit\",\n",
        "            \"quite\",\n",
        "            \"!q\",\n",
        "            \"q\",\n",
        "            \"done\",\n",
        "            \"finish\",\n",
        "            \"end\",\n",
        "            \"bye\",\n",
        "            \"good bye\",\n",
        "        ]\n",
        "\n",
        "        # check if user is exiting convesation\n",
        "        if strip_non_alpha(user_input) in exit_phrase_list:\n",
        "            print(\"\\nAll Done!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            assistant_says, context_history = go_user(user_input, context_history, use_this_model)\n",
        "\n",
        "            print( assistant_says )\n",
        "\n",
        "            # save dialogue so far\n",
        "            dialogue_history = context_history\n",
        "\n",
        "    # when out of loop, return history\n",
        "    return dialogue_history\n",
        "\n",
        "\n",
        "\n",
        "def propose_and_keep_discussing(context_history, use_this_model, questionaire_data):\n",
        "    \"\"\"\n",
        "    A very minimal chat with memory.\n",
        "\n",
        "    Uses:\n",
        "      query(input_string)\n",
        "      strip_non_alpha(text)\n",
        "    \"\"\"\n",
        "    still_talking = True\n",
        "    dialogue_history = \"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    ##########\n",
        "    # Propose\n",
        "    ##########\n",
        "    assistant_says, context_history = go_user(questionaire_data, context_history, use_this_model)\n",
        "\n",
        "    blurb = f\"\"\"\n",
        "\n",
        "    How is that draft? Are there any changes you want me to make?\n",
        "    \"\"\"\n",
        "\n",
        "    print( assistant_says + blurb )\n",
        "\n",
        "    # save dialogue so far\n",
        "    dialogue_history = context_history\n",
        "\n",
        "\n",
        "    ##################\n",
        "    # Keep Discussing\n",
        "    ##################\n",
        "    while still_talking:\n",
        "\n",
        "        user_input = input(\"Say...\")\n",
        "\n",
        "        exit_phrase_list = [\n",
        "            \"exit\",\n",
        "            \"quit\",\n",
        "            \"quite\",\n",
        "            \"!q\",\n",
        "            \"q\",\n",
        "            \"done\",\n",
        "            \"finish\",\n",
        "            \"end\",\n",
        "            \"bye\",\n",
        "            \"good bye\",\n",
        "        ]\n",
        "\n",
        "        # check if user is exiting convesation\n",
        "        if strip_non_alpha(user_input) in exit_phrase_list:\n",
        "            print(\"\\nAll Done!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            assistant_says, context_history = go_user(user_input, context_history, use_this_model)\n",
        "\n",
        "            blurb = f\"\"\"\n",
        "\n",
        "            How is that draft? Are there any changes you want me to make?\n",
        "            \"\"\"\n",
        "\n",
        "            print( assistant_says + blurb )\n",
        "\n",
        "            # save dialogue so far\n",
        "            dialogue_history = context_history\n",
        "\n",
        "    # when out of loop, return history\n",
        "    return dialogue_history\n",
        "\n",
        "\n",
        "\n",
        "# save history\n",
        "def record_history_save_files(dialogue_history):\n",
        "\n",
        "    date_time = dt.utcnow()\n",
        "    timestamp = date_time.strftime('%Y/%m/%d  %H:%M:%S:%f')\n",
        "    clean_timestamp = date_time.strftime('%Y%m%d%H%M')\n",
        "\n",
        "    # To save the data directly as a JSON file:\n",
        "\n",
        "    # Convert the Python dictionary list to a JSON string\n",
        "    json_data = json.dumps(dialogue_history)\n",
        "\n",
        "    # Open a file for writing in JSON format\n",
        "    with open(f'json_dialog_{clean_timestamp}.json', 'w') as json_file:\n",
        "        # Write the JSON string to the file\n",
        "        json_file.write(json_data)\n",
        "\n",
        "\n",
        "    # To save the data as a file readable as a script:\n",
        "\n",
        "    # Create a new file for writing\n",
        "    with open(f'script_dialog_{clean_timestamp}.txt', 'w') as script_file:\n",
        "\n",
        "        # add timestamp\n",
        "        text = timestamp + \"\\n\\n\"\n",
        "        script_file.write(text)\n",
        "\n",
        "        # Iterate over the dictionary list\n",
        "        for item in dialogue_history:\n",
        "            # Write the role and content of each item to the file, separated by a newline\n",
        "            script_file.write(f\"{item['role']}: {item['content']}\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Creation Prompts: Part 1\n",
        "\n",
        "Tech note: This sets a 'system prompt'"
      ],
      "metadata": {
        "id": "t7je4Jg6nU0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_extra_spaces(text):\n",
        "    # Use a regular expression to replace multiple spaces with a single space\n",
        "    cleaned_text = re.sub(' +', ' ', text)\n",
        "\n",
        "    # add a trailing space\n",
        "    cleaned_text += ' '\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def just_words(text):\n",
        "    # Split the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Join the words back together with a single space between each word\n",
        "    cleaned_text = ' '.join(words)\n",
        "\n",
        "    # add a trailing space\n",
        "    cleaned_text += ' '\n",
        "\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "5IMb_rPkoPF7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reset History\n",
        "context_history = []\n",
        "\n",
        "######################################\n",
        "# Enter your Personality request here\n",
        "######################################\n",
        "questionaire_result = f\"\"\"\n",
        "You are an assistant who is helping a coworker\n",
        "to write a job description for a job post. Take\n",
        "this information they provided and suggest a job descrption.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "####################\n",
        "# Model Team Member\n",
        "####################\n",
        "blurb = f\"\"\"\n",
        "1. A Model Team Member:\n",
        "Let's begin making a job description.\n",
        "First, is there a person you want want to\n",
        "use as an ideal model for this position\n",
        "about whom you have some specific information,\n",
        "such as their resume, coverletter, or their own\n",
        "description of there role, tasks, and skills?\n",
        "If so, please enter that text now. If not, say: None.\n",
        "\"\"\"\n",
        "\n",
        "# get user's data\n",
        "response = input(blurb)\n",
        "\n",
        "# blurb = just_words(blurb)\n",
        "\n",
        "# if user said anything, record it:\n",
        "if re.sub(r'[^\\w\\s]', '', response).strip().lower() != 'none':\n",
        "\n",
        "    front_matter = f\"\"\" This is a description of\n",
        "    a model employee:\n",
        "    \"\"\"\n",
        "\n",
        "    front_matter = just_words(front_matter)\n",
        "\n",
        "    questionaire_result += front_matter + response\n",
        "\n",
        "\n",
        "########\n",
        "# Tasks\n",
        "########\n",
        "blurb = f\"\"\"\n",
        "2. What tasks will that person be doing?\n",
        "Give examples and specifics where possible.\n",
        "\"\"\"\n",
        "\n",
        "response = input(blurb)\n",
        "\n",
        "front_matter = f\"\"\" This is a description of\n",
        "the task that the job will involve:\n",
        "\"\"\"\n",
        "\n",
        "front_matter = just_words(front_matter)\n",
        "\n",
        "questionaire_result += front_matter + response\n",
        "\n",
        "\n",
        "#####################\n",
        "# Skills & Abilities\n",
        "#####################\n",
        "blurb = f\"\"\"\n",
        "3. Skills & Abilities\n",
        "Do you know the skills and abilities\n",
        "that\n",
        "If so, please enter that text now. If not, say: None\n",
        "\"\"\"\n",
        "\n",
        "# get user's data\n",
        "response = input(blurb)\n",
        "\n",
        "# if user said anything, record it:\n",
        "# if response.strip().lower() != 'none':\n",
        "if re.sub(r'[^\\w\\s]', '', response).strip().lower() != 'none':\n",
        "\n",
        "    front_matter = f\"\"\" This is a description of\n",
        "    the skills and abilities that the employee will need:\n",
        "    \"\"\"\n",
        "\n",
        "    front_matter = just_words(front_matter)\n",
        "\n",
        "    questionaire_result += front_matter + response\n",
        "\n",
        "\n",
        "###################\n",
        "# Work Environment\n",
        "###################\n",
        "blurb = f\"\"\"\n",
        "4. What will the work-environment for this position be?\n",
        "Will they be working on a team, or alone?\n",
        "Will they be more managing a team, or managed?\n",
        "Who will they report to?\n",
        "Are there daily Standups?\n",
        "Give examples and specifics where possible.\n",
        "\"\"\"\n",
        "\n",
        "response = input(blurb)\n",
        "\n",
        "front_matter = f\"\"\" This is a description of the\n",
        "works/team environment for that position:\n",
        "\"\"\"\n",
        "\n",
        "front_matter = just_words(front_matter)\n",
        "\n",
        "questionaire_result += front_matter + response\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################\n",
        "# Specific Tools & Experience\n",
        "##############################\n",
        "blurb = f\"\"\"\n",
        "5. Are there specific tools or other experiences\n",
        "that the new employee should have? Take one at a time.\n",
        "What is the first required experience?\n",
        "If there are none, say: None\n",
        "\"\"\"\n",
        "\n",
        "# get user's data\n",
        "response = input(blurb)\n",
        "\n",
        "done_flag = False\n",
        "\n",
        "# if user said anything, record it:\n",
        "if re.sub(r'[^\\w\\s]', '', response).strip().lower() != 'none':\n",
        "\n",
        "    front_matter = f\"\"\" This is a description of\n",
        "    the skills and abilities that the employee will need:\n",
        "    \"\"\"\n",
        "\n",
        "    front_matter = just_words(front_matter)\n",
        "\n",
        "    questionaire_result += front_matter + response\n",
        "\n",
        "\n",
        "    blurb = f\"\"\"\n",
        "    If you want to required a number of years of experience,\n",
        "    do a quick web search on that tool to make sure\n",
        "    that the possible experience is not a shorter time\n",
        "    than you are requiring. E.g. Requiring five years\n",
        "    of experience with a tool that is two years old.\n",
        "\n",
        "    When you know how much experience you can realistically expect\n",
        "    please describe that requirement now. Be clear about a firm\n",
        "    requirement vs. a hope. For example if someone has nearly\n",
        "    that much experience, would you like them to apply?\n",
        "\n",
        "    If you do not require a duration of experience, say None.\n",
        "    \"\"\"\n",
        "\n",
        "    # get user's data\n",
        "    response = input(blurb)\n",
        "\n",
        "\n",
        "    # if user said anything, record it:\n",
        "    if re.sub(r'[^\\w\\s]', '', response).strip().lower() != 'none':\n",
        "\n",
        "        front_matter = f\"\"\" This is a detail of\n",
        "        how much experience is needed:\n",
        "        \"\"\"\n",
        "\n",
        "        front_matter = just_words(front_matter)\n",
        "\n",
        "        questionaire_result += front_matter + response\n",
        "\n",
        "else:\n",
        "    done_flag = True\n",
        "\n",
        "\n",
        "while done_flag is False:\n",
        "\n",
        "\n",
        "    blurb = f\"\"\"\n",
        "    What is the next experience required for this job?\n",
        "    If you are done, say: Done\n",
        "    \"\"\"\n",
        "\n",
        "    # get user's data\n",
        "    response = input(blurb)\n",
        "\n",
        "\n",
        "    # if user said anything, record it:\n",
        "    if re.sub(r'[^\\w\\s]', '', response).strip().lower() != 'done':\n",
        "\n",
        "        front_matter = f\"\"\" This is a description of\n",
        "        the skills and abilities that the employee will need:\n",
        "        \"\"\"\n",
        "\n",
        "        front_matter = just_words(front_matter)\n",
        "\n",
        "        questionaire_result += front_matter + response\n",
        "\n",
        "        blurb = f\"\"\"\n",
        "        If you want to require a number of years of experience,\n",
        "        do a quick web search on that tool to make sure\n",
        "        that the possible experience is not a shorter time\n",
        "        than you are requiring. E.g. Requiring five years\n",
        "        of experience with a tool that is two years old.\n",
        "\n",
        "        When you know how much experience you can realistically expect\n",
        "        please describe that requirement now. Be clear about a firm\n",
        "        requirement vs. a hope. For example if someone has nearly\n",
        "        that much experience, would you like them to apply?\n",
        "\n",
        "        If you do not require a duration of experience, say None.\n",
        "        \"\"\"\n",
        "\n",
        "        # get user's data\n",
        "        response = input(blurb)\n",
        "\n",
        "\n",
        "        # if user said anything, record it:\n",
        "        if re.sub(r'[^\\w\\s]', '', response).strip().lower() != 'none':\n",
        "\n",
        "            front_matter = f\"\"\" This is a detail of\n",
        "            how much experience is needed:\n",
        "            \"\"\"\n",
        "\n",
        "            front_matter = just_words(front_matter)\n",
        "\n",
        "            questionaire_result += front_matter + response\n",
        "\n",
        "    else:\n",
        "        done_flag = True\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##############################\n",
        "# Soft Skills\n",
        "##############################\n",
        "blurb = f\"\"\"\n",
        "6. Are there any soft skills, social skills, communication skills,\n",
        "language skills, translation skills, mediation or negotiation skills, etc.\n",
        "that are needed for this job?\n",
        "\n",
        "If you have nothing more to add, say: None\n",
        "\"\"\"\n",
        "\n",
        "# get user's data\n",
        "response = input(blurb)\n",
        "\n",
        "\n",
        "\n",
        "# if user said anything, record it:\n",
        "if re.sub(r'[^\\w\\s]', '', response).strip().lower() != 'none':\n",
        "\n",
        "    front_matter = f\"\"\" Here are addition details\n",
        "    about soft skills, social skills, communication skills,\n",
        "    language skills, translation skills, mediation or negotiation skills, etc.\n",
        "    that are needed for this job:\n",
        "    \"\"\"\n",
        "\n",
        "    front_matter = just_words(front_matter)\n",
        "\n",
        "    questionaire_result += front_matter + response\n",
        "\n",
        "\n",
        "\n",
        "##############################\n",
        "# Anything else?\n",
        "##############################\n",
        "blurb = f\"\"\"\n",
        "7. Is there anything else, any other details, drafts,\n",
        "comments, etc., or are you finished describing the position and role?\n",
        "\n",
        "If you have nothing more to add, say: None\n",
        "\"\"\"\n",
        "\n",
        "# get user's data\n",
        "response = input(blurb)\n",
        "\n",
        "\n",
        "\n",
        "# if user said anything, record it:\n",
        "if re.sub(r'[^\\w\\s]', '', response).strip().lower() != 'none':\n",
        "\n",
        "    front_matter = f\"\"\" Here are addition details\n",
        "    about the position and role:\n",
        "    \"\"\"\n",
        "\n",
        "    front_matter = just_words(front_matter)\n",
        "\n",
        "    questionaire_result += front_matter + response\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uloouSMrvhRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00810f9a-d78a-4cfe-b98d-51f348a37089"
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "1. A Model Team Member:\n",
            "Let's begin making a job description.\n",
            "First, is there a person you want want to \n",
            "use as an ideal model for this position\n",
            "about whom you have some specific information,\n",
            "such as their resume, coverletter, or their own\n",
            "description of there role, tasks, and skills?\n",
            "If so, please enter that text now. If not, say: None.\n",
            "none\n",
            "\n",
            "2. What tasks will that person be doing?\n",
            "Give examples and specifics where possible.\n",
            "making boxes\n",
            "\n",
            "3. Skills & Abilities\n",
            "Do you know the skills and abilities\n",
            "that \n",
            "If so, please enter that text now. If not, say: None\n",
            "using tape\n",
            "\n",
            "4. What will the work-environment for this position be? \n",
            "Will they be working on a team, or alone? \n",
            "Will they be more managing a team, or managed? \n",
            "Who will they report to? \n",
            "Are there daily Standups? \n",
            "Give examples and specifics where possible.\n",
            "managing a team \n",
            "\n",
            "5. Are there specific tools or other experiences \n",
            "that the new employee should have? Take one at a time. \n",
            "What is the first required experience? \n",
            "If there are none, say: None \n",
            "using a ruler\n",
            "\n",
            "    If you want to required a number of years of experience, \n",
            "    do a quick web search on that tool to make sure \n",
            "    that the possible experience is not a shorter time \n",
            "    than you are requiring. E.g. Requiring five years \n",
            "    of experience with a tool that is two years old. \n",
            "\n",
            "    When you know how much experience you can realistically expect \n",
            "    please describe that requirement now. Be clear about a firm \n",
            "    requirement vs. a hope. For example if someone has nearly \n",
            "    that much experience, would you like them to apply? \n",
            "\n",
            "    If you do not require a duration of experience, say None. \n",
            "    required two years of ruler experiene, firm.\n",
            "\n",
            "    What is the next experience required for this job?\n",
            "    If you are done, say: Done\n",
            "    done\n",
            "\n",
            "6. Is there anything else, any other details, drafts, \n",
            "comments, etc., or are you finished describing the position and role?\n",
            "\n",
            "If you have nothing more to add, say: None \n",
            "should be a people person\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_role = f\"\"\"\n",
        "You are an assistant who is helping a coworker\n",
        "to write a job description for a job post. Take\n",
        "this information they provided and suggest a job descrption.\n",
        "\"\"\"\n",
        "\n",
        "system_role = just_words(system_role)\n",
        "\n",
        "# Add the results of the questionaire to the conversation context.\n",
        "context_history.append(add_to_context_history('system', system_role))"
      ],
      "metadata": {
        "id": "nRuST9QyB5hm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime as dt\n",
        "\n",
        "# make readable time\n",
        "date_time = dt.utcnow()\n",
        "timestamp = date_time.strftime('%Y/%m/%d  %H:%M:%S:%f')\n",
        "clean_timestamp = date_time.strftime('%Y%m%d%H%M%S%f')\n",
        "\n",
        "instructions = f\"\"\"\n",
        "  Instructions: {timestamp}\n",
        "    - Enter your queries into the iput-box.\n",
        "    - Say 'quit' or 'exit', etc.,  to leave the conversation.\n",
        "\n",
        "\"\"\"\n",
        "print( instructions )\n",
        "\n",
        "print( context_history )\n",
        "\n",
        "# pick model\n",
        "use_this_model = \"open-mistral-7b\"\n",
        "\n",
        "# run chat\n",
        "dialogue_history = propose_and_keep_discussing(context_history, use_this_model, questionaire_result)\n",
        "\n",
        "# save history files\n",
        "record_history_save_files(dialogue_history)"
      ],
      "metadata": {
        "id": "kcab3MZ-wFIL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac6f3ff-7f89-4bef-d44e-80bdb1ed4b0e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Instructions: 2024/07/08  20:28:00:866251\n",
            "    - Enter your queries into the iput-box.\n",
            "    - Say 'quit' or 'exit', etc.,  to leave the conversation.\n",
            "\n",
            "\n",
            "[]\n",
            "Job Title: Box Assembly Team Leader\n",
            "\n",
            "Job Description:\n",
            "We are seeking an experienced and people-oriented Box Assembly Team Leader to join our team. The primary responsibility of this role will be to lead a team in the production of high-quality boxes using tape and a ruler. The ideal candidate will have at least two years of experience in box assembly, demonstrating a strong understanding of using a ruler for precise measurements and taping skills for secure box construction.\n",
            "\n",
            "Responsibilities:\n",
            "\n",
            "1. Lead a team in the production of boxes, ensuring all products meet quality standards and are completed on time.\n",
            "2. Utilize a ruler for accurate measurements and tape to construct sturdy and secure boxes.\n",
            "3. Oversee team members' work, providing guidance and feedback to improve their skills and efficiency.\n",
            "4. Foster a positive team environment, promoting good communication and collaboration among team members.\n",
            "5. Address any issues or concerns that arise during the production process in a timely and professional manner.\n",
            "6. Collaborate with other departments to ensure smooth operation of the box assembly line.\n",
            "\n",
            "Qualifications:\n",
            "\n",
            "1. At least two years of experience in box assembly, with a strong emphasis on ruler use and tape application.\n",
            "2. Excellent leadership and team management skills.\n",
            "3. Strong communication and interpersonal skills, with the ability to work effectively in a team environment.\n",
            "4. Attention to detail and strong problem-solving abilities.\n",
            "5. Ability to work in a fast-paced, production environment and meet tight deadlines.\n",
            "6. Passionate about delivering high-quality products and providing excellent customer service.\n",
            "\n",
            "    How is that draft? Are there any changes you want me to make?\n",
            "    \n",
            "Say...Could you add in a bit about a formal dress code, wearing a suit.\n",
            "Job Title: Box Assembly Team Leader\n",
            "\n",
            "Job Description:\n",
            "We are seeking an experienced and people-oriented Box Assembly Team Leader to join our team. The primary responsibility of this role will be to lead a team in the production of high-quality boxes using tape and a ruler. The ideal candidate will have at least two years of experience in box assembly, demonstrating a strong understanding of using a ruler for precise measurements and tape application.\n",
            "\n",
            "Responsibilities:\n",
            "\n",
            "1. Lead a team in the production of boxes, ensuring all products meet quality standards and are completed on time.\n",
            "2. Utilize a ruler for accurate measurements and tape to construct sturdy and secure boxes.\n",
            "3. Oversee team members' work, providing guidance and feedback to improve their skills and efficiency.\n",
            "4. Foster a positive team environment, promoting good communication and collaboration among team members.\n",
            "5. Address any issues or concerns that arise during the production process in a timely and professional manner.\n",
            "6. Collaborate with other departments to ensure smooth operation of the box assembly line.\n",
            "7. Maintain a professional appearance and adhere to a formal dress code, wearing a suit during work hours.\n",
            "\n",
            "Qualifications:\n",
            "\n",
            "1. At least two years of experience in box assembly, with a strong emphasis on ruler use and tape application.\n",
            "2. Excellent leadership and team management skills.\n",
            "3. Strong communication and interpersonal skills, with the ability to work effectively in a team environment.\n",
            "4. Attention to detail and strong problem-solving abilities.\n",
            "5. Ability to work in a fast-paced, production environment and meet tight deadlines.\n",
            "6. Passionate about delivering high-quality products and providing excellent customer service.\n",
            "\n",
            "            How is that draft? Are there any changes you want me to make?\n",
            "            \n",
            "Say...end\n",
            "\n",
            "All Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Transcript and results have been recorded as a file:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJrXTwM3CeMY",
        "outputId": "3d11d678-c78f-460c-c442-711f95625fef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript and results have been recorded as a file:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ_iiixBCaLi",
        "outputId": "157589b8-7cc8-4ac6-9e17-86b070b2344e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "json_dialog_202407081721.json  sample_data\t\t       script_dialog_202407082028.txt\n",
            "json_dialog_202407082028.json  script_dialog_202407081721.txt\n"
          ]
        }
      ]
    }
  ]
}